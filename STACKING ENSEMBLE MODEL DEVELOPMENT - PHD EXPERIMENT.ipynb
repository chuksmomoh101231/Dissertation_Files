{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beec90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e13aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4360406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('walmart_dataset_PhD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923f7862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sales        date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0       CA  d_1     12  2011-01-29     11101  ...     1  2011           NaN   \n",
       "1       CA  d_2     15  2011-01-30     11101  ...     1  2011           NaN   \n",
       "2       CA  d_3      0  2011-01-31     11101  ...     1  2011           NaN   \n",
       "3       CA  d_4      0  2011-02-01     11101  ...     2  2011           NaN   \n",
       "4       CA  d_5      0  2011-02-02     11101  ...     2  2011           NaN   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX snap_WI sell_price  \n",
       "0           NaN          NaN          NaN      No      No      No       0.46  \n",
       "1           NaN          NaN          NaN      No      No      No       0.46  \n",
       "2           NaN          NaN          NaN      No      No      No       0.46  \n",
       "3           NaN          NaN          NaN     Yes     Yes      No       0.46  \n",
       "4           NaN          NaN          NaN     Yes      No     Yes       0.46  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551c0839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46027957, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afc7b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46027957 entries, 0 to 46027956\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            object \n",
      " 1   item_id       object \n",
      " 2   dept_id       object \n",
      " 3   cat_id        object \n",
      " 4   store_id      object \n",
      " 5   state_id      object \n",
      " 6   d             object \n",
      " 7   sales         int64  \n",
      " 8   date          object \n",
      " 9   wm_yr_wk      int64  \n",
      " 10  weekday       object \n",
      " 11  wday          int64  \n",
      " 12  month         int64  \n",
      " 13  year          int64  \n",
      " 14  event_name_1  object \n",
      " 15  event_type_1  object \n",
      " 16  event_name_2  object \n",
      " 17  event_type_2  object \n",
      " 18  snap_CA       object \n",
      " 19  snap_TX       object \n",
      " 20  snap_WI       object \n",
      " 21  sell_price    float64\n",
      "dtypes: float64(1), int64(5), object(16)\n",
      "memory usage: 7.5+ GB\n"
     ]
    }
   ],
   "source": [
    "#get some basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8df5e8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401c856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>1.427294</td>\n",
       "      <td>4.310440</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>763.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>11373.480404</td>\n",
       "      <td>143.775567</td>\n",
       "      <td>11101.00</td>\n",
       "      <td>11243.00</td>\n",
       "      <td>11406.00</td>\n",
       "      <td>11511.00</td>\n",
       "      <td>11613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wday</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>3.996688</td>\n",
       "      <td>2.000825</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>6.398704</td>\n",
       "      <td>3.480230</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>2013.552382</td>\n",
       "      <td>1.470835</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sell_price</th>\n",
       "      <td>46027957.0</td>\n",
       "      <td>4.408089</td>\n",
       "      <td>3.403657</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5.84</td>\n",
       "      <td>107.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean         std       min       25%  \\\n",
       "sales       46027957.0      1.427294    4.310440      0.00      0.00   \n",
       "wm_yr_wk    46027957.0  11373.480404  143.775567  11101.00  11243.00   \n",
       "wday        46027957.0      3.996688    2.000825      1.00      2.00   \n",
       "month       46027957.0      6.398704    3.480230      1.00      3.00   \n",
       "year        46027957.0   2013.552382    1.470835   2011.00   2012.00   \n",
       "sell_price  46027957.0      4.408089    3.403657      0.01      2.18   \n",
       "\n",
       "                 50%       75%       max  \n",
       "sales           0.00      1.00    763.00  \n",
       "wm_yr_wk    11406.00  11511.00  11613.00  \n",
       "wday            4.00      6.00      7.00  \n",
       "month           6.00      9.00     12.00  \n",
       "year         2014.00   2015.00   2016.00  \n",
       "sell_price      3.47      5.84    107.32  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics of the numeric variables\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b667929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0.000000\n",
       "item_id          0.000000\n",
       "dept_id          0.000000\n",
       "cat_id           0.000000\n",
       "store_id         0.000000\n",
       "state_id         0.000000\n",
       "d                0.000000\n",
       "sales            0.000000\n",
       "date             0.000000\n",
       "wm_yr_wk         0.000000\n",
       "weekday          0.000000\n",
       "wday             0.000000\n",
       "month            0.000000\n",
       "year             0.000000\n",
       "event_name_1    91.990976\n",
       "event_type_1    91.990976\n",
       "event_name_2    99.794727\n",
       "event_type_2    99.794727\n",
       "snap_CA          0.000000\n",
       "snap_TX          0.000000\n",
       "snap_WI          0.000000\n",
       "sell_price       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isnull().sum()/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b19dc95",
   "metadata": {},
   "source": [
    "There are missing values in the dataset. The values are all over 90 percent and will all be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2c2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_rows = df.duplicated()\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicate_rows = duplicate_rows.sum()\n",
    "\n",
    "# Print the number of duplicate rows\n",
    "print(\"Number of duplicate rows:\", num_duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32ab34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales         1.000000\n",
      "wm_yr_wk     -0.038909\n",
      "wday         -0.032059\n",
      "month        -0.004179\n",
      "year         -0.038109\n",
      "sell_price   -0.150920\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = df['sales']\n",
    "\n",
    "# Calculate the correlations between x and all other variables in the dataset\n",
    "correlations = df.corrwith(x)\n",
    "\n",
    "# Print the correlations\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195debb",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321f1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the variables with over 90 percent missing values, and other categorical variables not needed.\n",
    "df.drop(['id','item_id','dept_id','cat_id','store_id','wm_yr_wk','weekday','wday',\n",
    "        'event_name_1','event_type_1','event_name_2','event_type_2','date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1f3936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_id    d  sales  month  year snap_CA snap_TX snap_WI  sell_price\n",
       "0       CA  d_1     12      1  2011      No      No      No        0.46\n",
       "1       CA  d_2     15      1  2011      No      No      No        0.46\n",
       "2       CA  d_3      0      1  2011      No      No      No        0.46\n",
       "3       CA  d_4      0      2  2011     Yes     Yes      No        0.46\n",
       "4       CA  d_5      0      2  2011     Yes      No     Yes        0.46"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9994d7",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "\n",
    "\n",
    "I will create moving averages for 28 window period. 28 window period was chosen because the goal is to predict demand every 28 days. I will aslo create a total price variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408905ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a simple moving average, exponential moving average and cumulative moving average for a 30 window period from a daily energy consumption variable and return the dataframe plus the created variables\n",
    "\n",
    "def create_moving_averages(df):\n",
    "    # Simple Moving Average\n",
    "    df['simple_moving_average']=df['sales'].rolling(window=28, min_periods=1).mean()\n",
    "    \n",
    "    # Exponential Moving Average\n",
    "    df['exp_weighted_moving_average']=df['sales'].ewm(span=28).mean()\n",
    "    \n",
    "    # Cumulative Moving Average\n",
    "    df['cum_moving_average']=df['sales'].expanding().mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_moving_averages(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29433444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_price'] = df['sales'] * df['sell_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23deec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>simple_moving_average</th>\n",
       "      <th>exp_weighted_moving_average</th>\n",
       "      <th>cum_moving_average</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.553571</td>\n",
       "      <td>13.50</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.709307</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.293346</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.40</td>\n",
       "      <td>4.848689</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_id    d  sales  month  year snap_CA snap_TX snap_WI  sell_price  \\\n",
       "0       CA  d_1     12      1  2011      No      No      No        0.46   \n",
       "1       CA  d_2     15      1  2011      No      No      No        0.46   \n",
       "2       CA  d_3      0      1  2011      No      No      No        0.46   \n",
       "3       CA  d_4      0      2  2011     Yes     Yes      No        0.46   \n",
       "4       CA  d_5      0      2  2011     Yes      No     Yes        0.46   \n",
       "\n",
       "   simple_moving_average  exp_weighted_moving_average  cum_moving_average  \\\n",
       "0                  12.00                    12.000000               12.00   \n",
       "1                  13.50                    13.553571               13.50   \n",
       "2                   9.00                     8.709307                9.00   \n",
       "3                   6.75                     6.293346                6.75   \n",
       "4                   5.40                     4.848689                5.40   \n",
       "\n",
       "   total_price  \n",
       "0         5.52  \n",
       "1         6.90  \n",
       "2         0.00  \n",
       "3         0.00  \n",
       "4         0.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9dbdbf",
   "metadata": {},
   "source": [
    "## MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ccf2b",
   "metadata": {},
   "source": [
    "The categorical values will be encoded using pandas factorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449a4933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object variable columns: ['state_id', 'd', 'snap_CA', 'snap_TX', 'snap_WI']\n"
     ]
    }
   ],
   "source": [
    "# Get a subset of the DataFrame containing only object variables\n",
    "object_variables = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Get the column names of the object variables\n",
    "object_columns = object_variables.columns.tolist()\n",
    "\n",
    "# Print the column names of the object variables\n",
    "print(\"Object variable columns:\", object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['state_id', 'snap_CA', 'snap_TX', 'snap_WI']] = df[['state_id', 'snap_CA', 'snap_TX', 'snap_WI']].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb58cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>simple_moving_average</th>\n",
       "      <th>exp_weighted_moving_average</th>\n",
       "      <th>cum_moving_average</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.553571</td>\n",
       "      <td>13.50</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.709307</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.293346</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.40</td>\n",
       "      <td>4.848689</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_id    d  sales  month  year  snap_CA  snap_TX  snap_WI  sell_price  \\\n",
       "0         0  d_1     12      1  2011        0        0        0        0.46   \n",
       "1         0  d_2     15      1  2011        0        0        0        0.46   \n",
       "2         0  d_3      0      1  2011        0        0        0        0.46   \n",
       "3         0  d_4      0      2  2011        1        1        0        0.46   \n",
       "4         0  d_5      0      2  2011        1        0        1        0.46   \n",
       "\n",
       "   simple_moving_average  exp_weighted_moving_average  cum_moving_average  \\\n",
       "0                  12.00                    12.000000               12.00   \n",
       "1                  13.50                    13.553571               13.50   \n",
       "2                   9.00                     8.709307                9.00   \n",
       "3                   6.75                     6.293346                6.75   \n",
       "4                   5.40                     4.848689                5.40   \n",
       "\n",
       "   total_price  \n",
       "0         5.52  \n",
       "1         6.90  \n",
       "2         0.00  \n",
       "3         0.00  \n",
       "4         0.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6abc508",
   "metadata": {},
   "source": [
    "**Create Train and Test Datasets**\n",
    "\n",
    "Since the objective is to predict demand every 28 days, the last 28 days of sale will be extracted as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504032bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = df.d.str.strip('d_') #remove the characters from the string and then convert object to numneric to enable extracting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ba7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variable's data type will be changed to integer to enable the extraction of the test data\n",
    "\n",
    "df['d'] = df['d'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "950a6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## downcasting loop\n",
    "for column in df:\n",
    "    if df[column].dtype == 'float64':\n",
    "        df[column]=pd.to_numeric(df[column], downcast='float')\n",
    "    if df[column].dtype == 'int64':\n",
    "        df[column]=pd.to_numeric(df[column], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd10b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46027957 entries, 0 to 46027956\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   state_id                     int8   \n",
      " 1   d                            int16  \n",
      " 2   sales                        int16  \n",
      " 3   month                        int8   \n",
      " 4   year                         int16  \n",
      " 5   snap_CA                      int8   \n",
      " 6   snap_TX                      int8   \n",
      " 7   snap_WI                      int8   \n",
      " 8   sell_price                   float32\n",
      " 9   simple_moving_average        float32\n",
      " 10  exp_weighted_moving_average  float32\n",
      " 11  cum_moving_average           float32\n",
      " 12  total_price                  float32\n",
      "dtypes: float32(5), int16(3), int8(5)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "665902c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the train and test datasets\n",
    "\n",
    "def extract_train_test_samples(df):\n",
    "    # Get the minimum and maximum values of the 'd' column\n",
    "    d_min = df['d'].min()\n",
    "    d_max = df['d'].max()\n",
    "    \n",
    "    # Extract the test sample in the order of df[df['d'] >= d_max - 28]\n",
    "    test_sample = df[df['d'] >= d_max - 28].sort_values(by='d')\n",
    "    \n",
    "    # Extract the train sample in the order of df[(df['d'] >= d_min) & (df['d'] < d_max - 28)]\n",
    "    train_sample = df[(df['d'] >= d_min) & (df['d'] < d_max - 28)].sort_values(by='d')\n",
    "    \n",
    "    return train_sample, test_sample\n",
    "\n",
    "train_sample, test_sample = extract_train_test_samples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9105ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       state_id  d  sales  month  year  snap_CA  snap_TX  snap_WI  sell_price  \\\n",
      "0             0  1     12      1  2011        0        0        0        0.46   \n",
      "31906         1  1      0      1  2011        0        0        0        3.67   \n",
      "31899         1  1      0      1  2011        0        0        0       12.12   \n",
      "31892         1  1      1      1  2011        0        0        0        2.57   \n",
      "31885         1  1      1      1  2011        0        0        0        6.44   \n",
      "\n",
      "       simple_moving_average  exp_weighted_moving_average  cum_moving_average  \\\n",
      "0                  12.000000                    12.000000           12.000000   \n",
      "31906               0.892857                     0.709585            2.601843   \n",
      "31899               0.750000                     0.653497            2.602226   \n",
      "31892               1.035714                     0.929516            2.602734   \n",
      "31885               1.428571                     1.313224            2.603243   \n",
      "\n",
      "       total_price  \n",
      "0             5.52  \n",
      "31906         0.00  \n",
      "31899         0.00  \n",
      "31892         2.57  \n",
      "31885         6.44  \n",
      "(45143747, 13)\n",
      "          state_id     d  sales  month  year  snap_CA  snap_TX  snap_WI  \\\n",
      "45113258         0  1885      1      3  2016        0        0        0   \n",
      "45282441         2  1885      1      3  2016        0        0        0   \n",
      "45172254         0  1885      5      3  2016        0        0        0   \n",
      "45172261         0  1885     17      3  2016        0        0        0   \n",
      "45282434         2  1885      0      3  2016        0        0        0   \n",
      "\n",
      "          sell_price  simple_moving_average  exp_weighted_moving_average  \\\n",
      "45113258        8.26               1.071429                     1.392841   \n",
      "45282441        2.68               1.357143                     1.007385   \n",
      "45172254        1.00               0.892857                     1.434569   \n",
      "45172261        2.48               1.928571                     3.061044   \n",
      "45282434        1.98               1.607143                     1.349851   \n",
      "\n",
      "          cum_moving_average  total_price  \n",
      "45113258            1.427775         8.26  \n",
      "45282441            1.427358         2.68  \n",
      "45172254            1.427874         5.00  \n",
      "45172261            1.427875        42.16  \n",
      "45282434            1.427358         0.00  \n",
      "(884210, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_sample.head())\n",
    "print(train_sample.shape)\n",
    "print(test_sample.head())\n",
    "print(test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257653d7",
   "metadata": {},
   "source": [
    "The function below trains base models from the Random Forest and LightGBM algorithms and evaluated using cross-validation with 5 folds and hold out test data, after which they will be tuned using Economical Hyperparameter Optimization With Blended Search Strategy and same evaluation carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f9ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,cross_validate\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "def evaluate_models(X, y):\n",
    "    # define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    \n",
    "    lgb_model = LGBMRegressor(objective='regression',metric='mse',n_jobs=50)\n",
    "    rf_model = RandomForestRegressor(n_jobs=50)\n",
    "    \n",
    "    \n",
    "    # Perform 5-fold cross-validation using MAE, MSE, RMSE and R2 metric and printing their mean scores\n",
    "     # Define the scorer dictionary\n",
    "    \n",
    "    scorer = {\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'RMSE': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n",
    "    'R2': make_scorer(r2_score)\n",
    "}\n",
    "    \n",
    "    lgb_scores = cross_validate(lgb_model, X_train,y_train, cv=5, scoring= scorer,n_jobs=50)\n",
    "    rf_scores = cross_validate(rf_model, X_train,y_train, cv=5, scoring= scorer,n_jobs=50)\n",
    "    \n",
    "    \n",
    "    # Compute mean scores and store in a pandas dataframe\n",
    "    cross_val_avg  = pd.DataFrame({\n",
    "        \n",
    "    'LightGBM_MAE': lgb_scores['test_MAE'].mean(),\n",
    "    'LightGBM_MSE': lgb_scores['test_MSE'].mean(),\n",
    "    'LightGBM_RMSE': lgb_scores['test_RMSE'].mean(),\n",
    "    'LightGBM_R2': lgb_scores['test_R2'].mean(),\n",
    "    'Random Forest_MAE': rf_scores['test_MAE'].mean(),\n",
    "    'Random Forest_MSE': rf_scores['test_MSE'].mean(),\n",
    "    'Random Forest_RMSE': rf_scores['test_RMSE'].mean(),\n",
    "    'Random Forest_R2': rf_scores['test_R2'].mean()\n",
    "        \n",
    "}, index=[0])\n",
    "    \n",
    "    # Perform 5-fold cross-validation using MSE metric\n",
    "    \n",
    "    score = make_scorer(mean_squared_error)\n",
    "    lgb_scores = cross_val_score(lgb_model, X_train,y_train, cv=5, scoring=score,n_jobs=50)\n",
    "    rf_scores = cross_val_score(rf_model, X_train,y_train, cv=5, scoring=score,n_jobs=50)\n",
    "    \n",
    "      # Save cross-validation scores to dataframe\n",
    "    cross_val = pd.DataFrame({\n",
    "        'LightGBM': lgb_scores,\n",
    "        'Random Forest': rf_scores\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "    # Fit models on the train dataset\n",
    "    lgb_model.fit(X_train,y_train)\n",
    "    rf_model.fit(X_train,y_train)\n",
    "    \n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred_lgb = lgb_model.predict(X_test)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluate models with test data using MAE, MSE, RMSE, and R2 and save to dataframe\n",
    "    eval_test_data = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
    "        'LightGBM': [mean_absolute_error(y_test, y_pred_lgb), \n",
    "                     mean_squared_error(y_test, y_pred_lgb), \n",
    "                     np.sqrt(mean_squared_error(y_test, y_pred_lgb)), \n",
    "                     r2_score(y_test, y_pred_lgb)],\n",
    "        'Random Forest': [mean_absolute_error(y_test, y_pred_rf), \n",
    "                     mean_squared_error(y_test, y_pred_rf), \n",
    "                     np.sqrt(mean_squared_error(y_test, y_pred_rf)), \n",
    "                     r2_score(y_test, y_pred_rf)]\n",
    "    })\n",
    "\n",
    "    return cross_val_avg, cross_val, eval_test_data\n",
    "\n",
    "cross_val_avg, cross_val, eval_test_data = evaluate_models(df.drop(columns=['sales']), df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5df4ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM_MAE</th>\n",
       "      <th>LightGBM_MSE</th>\n",
       "      <th>LightGBM_RMSE</th>\n",
       "      <th>LightGBM_R2</th>\n",
       "      <th>Random Forest_MAE</th>\n",
       "      <th>Random Forest_MSE</th>\n",
       "      <th>Random Forest_RMSE</th>\n",
       "      <th>Random Forest_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050048</td>\n",
       "      <td>0.535113</td>\n",
       "      <td>0.702368</td>\n",
       "      <td>0.973519</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.999107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM_MAE  LightGBM_MSE  LightGBM_RMSE  LightGBM_R2  Random Forest_MAE  \\\n",
       "0      0.050048      0.535113       0.702368     0.973519           0.000956   \n",
       "\n",
       "   Random Forest_MSE  Random Forest_RMSE  Random Forest_R2  \n",
       "0           0.017899            0.126221          0.999107  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13948621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.027485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.778483</td>\n",
       "      <td>0.020626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.502658</td>\n",
       "      <td>0.015593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211330</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239615</td>\n",
       "      <td>0.007105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM  Random Forest\n",
       "0  0.943478       0.027485\n",
       "1  0.778483       0.020626\n",
       "2  0.502658       0.015593\n",
       "3  0.211330       0.002369\n",
       "4  0.239615       0.007105"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48e41107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.046438</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.191209</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.437274</td>\n",
       "      <td>0.026276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.985490</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  LightGBM  Random Forest\n",
       "0    MAE  0.046438       0.000290\n",
       "1    MSE  0.191209       0.000690\n",
       "2   RMSE  0.437274       0.026276\n",
       "3     R2  0.985490       0.999948"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e7016",
   "metadata": {},
   "source": [
    "The models did not overfit judging from the cross-validation scores. Hyperparameter tuning will be conducted on the models to see if improved accuracy will be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5deada",
   "metadata": {},
   "source": [
    "## LightGBM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65e0257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-12 22:18:25] {1693} INFO - task = regression\n",
      "[flaml.automl.logger: 07-12 22:18:25] {1700} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 07-12 22:18:25] {1703} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 07-12 22:18:51] {1801} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 07-12 22:18:51] {1911} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.logger: 07-12 22:18:51] {2221} INFO - iteration 0, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2023-07-12 22:18:51,017]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-12 22:22:04] {2347} INFO - Estimated sufficient time budget=1935144s. Estimated necessary time budget=1935s.\n",
      "[flaml.automl.logger: 07-12 22:22:04] {2394} INFO -  at 345.7s,\testimator lgbm's best error=12.5757,\tbest estimator lgbm's best error=12.5757\n",
      "[flaml.automl.logger: 07-12 22:22:04] {2221} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:25:18] {2394} INFO -  at 540.2s,\testimator lgbm's best error=12.5757,\tbest estimator lgbm's best error=12.5757\n",
      "[flaml.automl.logger: 07-12 22:25:18] {2221} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:28:35] {2394} INFO -  at 736.4s,\testimator lgbm's best error=7.1176,\tbest estimator lgbm's best error=7.1176\n",
      "[flaml.automl.logger: 07-12 22:28:35] {2221} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:32:02] {2394} INFO -  at 944.0s,\testimator lgbm's best error=1.7381,\tbest estimator lgbm's best error=1.7381\n",
      "[flaml.automl.logger: 07-12 22:32:02] {2221} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:35:17] {2394} INFO -  at 1139.1s,\testimator lgbm's best error=1.7381,\tbest estimator lgbm's best error=1.7381\n",
      "[flaml.automl.logger: 07-12 22:35:17] {2221} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:38:47] {2394} INFO -  at 1349.1s,\testimator lgbm's best error=1.5609,\tbest estimator lgbm's best error=1.5609\n",
      "[flaml.automl.logger: 07-12 22:38:47] {2221} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:42:15] {2394} INFO -  at 1556.9s,\testimator lgbm's best error=1.5609,\tbest estimator lgbm's best error=1.5609\n",
      "[flaml.automl.logger: 07-12 22:42:15] {2221} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:45:30] {2394} INFO -  at 1751.7s,\testimator lgbm's best error=1.5609,\tbest estimator lgbm's best error=1.5609\n",
      "[flaml.automl.logger: 07-12 22:45:30] {2221} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:49:54] {2394} INFO -  at 2015.8s,\testimator lgbm's best error=1.0261,\tbest estimator lgbm's best error=1.0261\n",
      "[flaml.automl.logger: 07-12 22:49:54] {2221} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 22:53:25] {2394} INFO -  at 2227.0s,\testimator lgbm's best error=1.0261,\tbest estimator lgbm's best error=1.0261\n",
      "[flaml.automl.logger: 07-12 22:53:25] {2221} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 23:03:19] {2394} INFO -  at 2820.8s,\testimator lgbm's best error=0.4811,\tbest estimator lgbm's best error=0.4811\n",
      "[flaml.automl.logger: 07-12 23:03:19] {2221} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 23:18:02] {2394} INFO -  at 3703.3s,\testimator lgbm's best error=0.3095,\tbest estimator lgbm's best error=0.3095\n",
      "[flaml.automl.logger: 07-12 23:18:02] {2221} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 23:27:58] {2394} INFO -  at 4299.6s,\testimator lgbm's best error=0.3095,\tbest estimator lgbm's best error=0.3095\n",
      "[flaml.automl.logger: 07-12 23:27:58] {2221} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 23:43:19] {2394} INFO -  at 5220.6s,\testimator lgbm's best error=0.1537,\tbest estimator lgbm's best error=0.1537\n",
      "[flaml.automl.logger: 07-12 23:43:19] {2221} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 07-12 23:58:06] {2394} INFO -  at 6107.4s,\testimator lgbm's best error=0.1537,\tbest estimator lgbm's best error=0.1537\n",
      "[flaml.automl.logger: 07-12 23:58:06] {2221} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 00:11:50] {2394} INFO -  at 6931.3s,\testimator lgbm's best error=0.0960,\tbest estimator lgbm's best error=0.0960\n",
      "[flaml.automl.logger: 07-13 00:11:50] {2221} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 00:18:33] {2394} INFO -  at 7334.5s,\testimator lgbm's best error=0.0960,\tbest estimator lgbm's best error=0.0960\n",
      "[flaml.automl.logger: 07-13 00:18:33] {2221} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 00:34:09] {2394} INFO -  at 8270.3s,\testimator lgbm's best error=0.0960,\tbest estimator lgbm's best error=0.0960\n",
      "[flaml.automl.logger: 07-13 00:34:09] {2221} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 00:43:53] {2394} INFO -  at 8854.8s,\testimator lgbm's best error=0.0895,\tbest estimator lgbm's best error=0.0895\n",
      "[flaml.automl.logger: 07-13 00:43:53] {2221} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 00:56:32] {2394} INFO -  at 9613.5s,\testimator lgbm's best error=0.0895,\tbest estimator lgbm's best error=0.0895\n",
      "[flaml.automl.logger: 07-13 00:56:32] {2221} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:02:37] {2394} INFO -  at 9978.8s,\testimator lgbm's best error=0.0841,\tbest estimator lgbm's best error=0.0841\n",
      "[flaml.automl.logger: 07-13 01:02:37] {2221} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:12:35] {2394} INFO -  at 10576.5s,\testimator lgbm's best error=0.0841,\tbest estimator lgbm's best error=0.0841\n",
      "[flaml.automl.logger: 07-13 01:12:35] {2221} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:21:03] {2394} INFO -  at 11084.9s,\testimator lgbm's best error=0.0811,\tbest estimator lgbm's best error=0.0811\n",
      "[flaml.automl.logger: 07-13 01:21:03] {2221} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:27:01] {2394} INFO -  at 11442.6s,\testimator lgbm's best error=0.0811,\tbest estimator lgbm's best error=0.0811\n",
      "[flaml.automl.logger: 07-13 01:27:01] {2221} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:37:18] {2394} INFO -  at 12060.0s,\testimator lgbm's best error=0.0754,\tbest estimator lgbm's best error=0.0754\n",
      "[flaml.automl.logger: 07-13 01:37:18] {2221} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:46:10] {2394} INFO -  at 12591.6s,\testimator lgbm's best error=0.0754,\tbest estimator lgbm's best error=0.0754\n",
      "[flaml.automl.logger: 07-13 01:46:10] {2221} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 01:54:53] {2394} INFO -  at 13115.0s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 01:54:53] {2221} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:05:09] {2394} INFO -  at 13730.2s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:05:09] {2221} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:18:55] {2394} INFO -  at 14556.2s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:18:55] {2221} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:24:34] {2394} INFO -  at 14895.4s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:24:34] {2221} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:31:03] {2394} INFO -  at 15284.7s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:31:03] {2221} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:42:27] {2394} INFO -  at 15969.2s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:42:27] {2221} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 02:48:17] {2394} INFO -  at 16318.5s,\testimator lgbm's best error=0.0605,\tbest estimator lgbm's best error=0.0605\n",
      "[flaml.automl.logger: 07-13 02:48:17] {2221} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 03:03:52] {2394} INFO -  at 17254.1s,\testimator lgbm's best error=0.0588,\tbest estimator lgbm's best error=0.0588\n",
      "[flaml.automl.logger: 07-13 03:03:52] {2221} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 03:14:34] {2394} INFO -  at 17895.6s,\testimator lgbm's best error=0.0588,\tbest estimator lgbm's best error=0.0588\n",
      "[flaml.automl.logger: 07-13 03:14:34] {2221} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 03:38:20] {2394} INFO -  at 19321.9s,\testimator lgbm's best error=0.0588,\tbest estimator lgbm's best error=0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-13 03:38:20] {2221} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 04:43:42] {2394} INFO -  at 23244.1s,\testimator lgbm's best error=0.0588,\tbest estimator lgbm's best error=0.0588\n",
      "[flaml.automl.logger: 07-13 04:43:42] {2221} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 04:49:14] {2394} INFO -  at 23575.6s,\testimator lgbm's best error=0.0588,\tbest estimator lgbm's best error=0.0588\n",
      "[flaml.automl.logger: 07-13 04:49:14] {2221} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 05:19:28] {2394} INFO -  at 25390.0s,\testimator lgbm's best error=0.0562,\tbest estimator lgbm's best error=0.0562\n",
      "[flaml.automl.logger: 07-13 05:19:28] {2221} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 05:34:37] {2394} INFO -  at 26298.4s,\testimator lgbm's best error=0.0562,\tbest estimator lgbm's best error=0.0562\n",
      "[flaml.automl.logger: 07-13 05:34:37] {2221} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 06:52:34] {2394} INFO -  at 30976.1s,\testimator lgbm's best error=0.0562,\tbest estimator lgbm's best error=0.0562\n",
      "[flaml.automl.logger: 07-13 06:52:34] {2221} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 07:05:36] {2394} INFO -  at 31758.1s,\testimator lgbm's best error=0.0562,\tbest estimator lgbm's best error=0.0562\n",
      "[flaml.automl.logger: 07-13 07:05:36] {2221} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 07:14:25] {2394} INFO -  at 32286.6s,\testimator lgbm's best error=0.0562,\tbest estimator lgbm's best error=0.0562\n",
      "[flaml.automl.logger: 07-13 07:14:25] {2221} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 09:20:14] {2394} INFO -  at 39835.4s,\testimator lgbm's best error=0.0553,\tbest estimator lgbm's best error=0.0553\n",
      "[flaml.automl.logger: 07-13 09:20:14] {2221} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 13:14:34] {2394} INFO -  at 53895.3s,\testimator lgbm's best error=0.0553,\tbest estimator lgbm's best error=0.0553\n",
      "[flaml.automl.logger: 07-13 13:42:19] {2630} INFO - retrain lgbm for 1665.6s\n",
      "[flaml.automl.logger: 07-13 13:42:19] {2633} INFO - retrained model: LGBMRegressor(learning_rate=0.04057886825523183, max_bin=1023,\n",
      "              min_child_samples=9, n_estimators=4641, n_jobs=50, num_leaves=17,\n",
      "              reg_alpha=0.00770959807729146, reg_lambda=0.05173294676341311,\n",
      "              verbose=-1)\n",
      "[flaml.automl.logger: 07-13 13:42:19] {1941} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-13 13:42:19] {1942} INFO - Time taken to find the best model: 39835.36403942108\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "def tune_lightgbm(X, y):\n",
    "    \n",
    "    # define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    # define the optimization function\n",
    "    lgb_tune = AutoML()\n",
    "    \n",
    "\n",
    "    # define the setting for optimization\n",
    "    \n",
    "    settings = {\n",
    "    \"time_budget\": 54000,  # total running time in seconds\n",
    "    \"metric\": 'mse',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": ['lgbm'],  # list of ML learners; we tune lightgbm in this example\n",
    "    \"task\": 'regression'  # task type  \n",
    "\n",
    "}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # run flaml optimization to find the best hyperparameters for the lightgbm\n",
    "    lgb_tune.fit(X_train, y_train,**settings,n_jobs=50,early_stop=True,hpo_method='bs',eval_method='cv',n_splits=5)\n",
    "    \n",
    "    # return the best hyperparameters and the best score\n",
    "    return lgb_tune.best_config\n",
    "\n",
    "best_config = tune_lightgbm(df.drop(columns=['sales']), df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f5bd8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4641,\n",
       " 'num_leaves': 17,\n",
       " 'min_child_samples': 9,\n",
       " 'learning_rate': 0.04057886825523183,\n",
       " 'log_max_bin': 10,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'reg_alpha': 0.00770959807729146,\n",
       " 'reg_lambda': 0.05173294676341311}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293bb973",
   "metadata": {},
   "source": [
    "**The lightgbm model will be retrained using the tuned paramaters, and cross-validation and hold-out data evaluation will be done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51b308f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y):\n",
    "    # re-define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    #re-define the model function with the tuned hyperparameter\n",
    "    lgb_model_tuned = LGBMRegressor(learning_rate=0.04057886825523183, max_bin=1023,\n",
    "                                    min_child_samples=9, n_estimators=4641, n_jobs=50, num_leaves=17,\n",
    "                                    reg_alpha=0.00770959807729146, reg_lambda=0.05173294676341311,\n",
    "                                    verbose=-1,objective='regression',metric='mse')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Perform 5-fold cross-validation using MAE, MSE, RMSE and R2 metric and printing their mean scores\n",
    "     # Define the scorer dictionary\n",
    "    \n",
    "    scorer = {\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'RMSE': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n",
    "    'R2': make_scorer(r2_score)\n",
    "}\n",
    "\n",
    "    lgb_scores = cross_validate(lgb_model_tuned, X_train,y_train, cv=5, scoring= scorer,n_jobs=50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute mean scores and store in a pandas dataframe\n",
    "    cross_val_avg  = pd.DataFrame({\n",
    "        \n",
    "    'MAE': lgb_scores['test_MAE'].mean(),\n",
    "    'MSE': lgb_scores['test_MSE'].mean(),\n",
    "    'RMSE': lgb_scores['test_RMSE'].mean(),\n",
    "    'R2': lgb_scores['test_R2'].mean()\n",
    "\n",
    "        \n",
    "}, index=[0])\n",
    "    \n",
    "    # Perform 5-fold cross-validation using MSE metric\n",
    "    \n",
    "    score = make_scorer(mean_squared_error)\n",
    "    lgb_scores = cross_val_score(lgb_model_tuned, X_train,y_train, cv=5, scoring=score,n_jobs=50)\n",
    "    \n",
    "      # Save cross-validation scores to dataframe\n",
    "    cross_val = pd.DataFrame({\n",
    "        'LightGBM': lgb_scores\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "    # Fit models on the train dataset\n",
    "    lgb_model_tuned.fit(X_train,y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred_lgb = lgb_model_tuned.predict(X_test)\n",
    "    \n",
    "\n",
    "    # Evaluate models with test data using MAE, MSE, RMSE, and R2 and save to dataframe\n",
    "    eval_test_data = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
    "        'LightGBM': [mean_absolute_error(y_test, y_pred_lgb), \n",
    "                     mean_squared_error(y_test, y_pred_lgb), \n",
    "                     np.sqrt(mean_squared_error(y_test, y_pred_lgb)), \n",
    "                     r2_score(y_test, y_pred_lgb)]\n",
    "    })\n",
    "\n",
    "    return cross_val_avg, cross_val, eval_test_data\n",
    "\n",
    "cross_val_avg, cross_val, eval_test_data = evaluate_models(df.drop(columns=['sales']), df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc527577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.077312</td>\n",
       "      <td>0.256531</td>\n",
       "      <td>0.996349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       MSE      RMSE        R2\n",
       "0  0.009177  0.077312  0.256531  0.996349"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "758ff390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM\n",
       "0  0.166571\n",
       "1  0.125820\n",
       "2  0.033597\n",
       "3  0.015332\n",
       "4  0.045238"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f9aa3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.008312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.009737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.098676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  LightGBM\n",
       "0    MAE  0.008312\n",
       "1    MSE  0.009737\n",
       "2   RMSE  0.098676\n",
       "3     R2  0.999261"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698dd7c",
   "metadata": {},
   "source": [
    "The tuned lightgbm model has an improved accuracy significantly and did not overfit judging by the cross-validation evaluations. The tuned model will be used to build the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d3f3a",
   "metadata": {},
   "source": [
    "## RandomForest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "560f3c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-13 23:15:55] {1693} INFO - task = regression\n",
      "[flaml.automl.logger: 07-13 23:15:55] {1700} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 07-13 23:15:55] {1703} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 07-13 23:16:21] {1801} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 07-13 23:16:21] {1911} INFO - List of ML learners in AutoML Run: ['rf']\n",
      "[flaml.automl.logger: 07-13 23:16:21] {2221} INFO - iteration 0, current learner rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2023-07-13 23:16:21,453]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-13 23:24:30] {2347} INFO - Estimated sufficient time budget=4885896s. Estimated necessary time budget=4886s.\n",
      "[flaml.automl.logger: 07-13 23:24:30] {2394} INFO -  at 642.8s,\testimator rf's best error=8.9506,\tbest estimator rf's best error=8.9506\n",
      "[flaml.automl.logger: 07-13 23:24:30] {2221} INFO - iteration 1, current learner rf\n",
      "[flaml.automl.logger: 07-13 23:37:07] {2394} INFO -  at 1400.7s,\testimator rf's best error=2.2522,\tbest estimator rf's best error=2.2522\n",
      "[flaml.automl.logger: 07-13 23:37:07] {2221} INFO - iteration 2, current learner rf\n",
      "[flaml.automl.logger: 07-13 23:51:29] {2394} INFO -  at 2262.4s,\testimator rf's best error=2.2522,\tbest estimator rf's best error=2.2522\n",
      "[flaml.automl.logger: 07-13 23:51:29] {2221} INFO - iteration 3, current learner rf\n",
      "[flaml.automl.logger: 07-14 00:08:57] {2394} INFO -  at 3310.2s,\testimator rf's best error=0.5353,\tbest estimator rf's best error=0.5353\n",
      "[flaml.automl.logger: 07-14 00:08:57] {2221} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 07-14 00:29:44] {2394} INFO -  at 4557.3s,\testimator rf's best error=0.1183,\tbest estimator rf's best error=0.1183\n",
      "[flaml.automl.logger: 07-14 00:29:44] {2221} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 07-14 00:47:00] {2394} INFO -  at 5593.0s,\testimator rf's best error=0.1183,\tbest estimator rf's best error=0.1183\n",
      "[flaml.automl.logger: 07-14 00:47:00] {2221} INFO - iteration 6, current learner rf\n",
      "[flaml.automl.logger: 07-14 01:09:23] {2394} INFO -  at 6936.6s,\testimator rf's best error=0.0840,\tbest estimator rf's best error=0.0840\n",
      "[flaml.automl.logger: 07-14 01:09:23] {2221} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 07-14 01:30:16] {2394} INFO -  at 8189.5s,\testimator rf's best error=0.0840,\tbest estimator rf's best error=0.0840\n",
      "[flaml.automl.logger: 07-14 01:30:16] {2221} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 07-14 01:49:07] {2394} INFO -  at 9319.9s,\testimator rf's best error=0.0666,\tbest estimator rf's best error=0.0666\n",
      "[flaml.automl.logger: 07-14 01:49:07] {2221} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 07-14 01:59:31] {2394} INFO -  at 9944.4s,\testimator rf's best error=0.0666,\tbest estimator rf's best error=0.0666\n",
      "[flaml.automl.logger: 07-14 01:59:31] {2221} INFO - iteration 10, current learner rf\n",
      "[flaml.automl.logger: 07-14 02:15:19] {2394} INFO -  at 10892.0s,\testimator rf's best error=0.0666,\tbest estimator rf's best error=0.0666\n",
      "[flaml.automl.logger: 07-14 02:15:19] {2221} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 07-14 02:45:41] {2394} INFO -  at 12713.9s,\testimator rf's best error=0.0349,\tbest estimator rf's best error=0.0349\n",
      "[flaml.automl.logger: 07-14 02:45:41] {2221} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 07-14 02:59:20] {2394} INFO -  at 13533.8s,\testimator rf's best error=0.0349,\tbest estimator rf's best error=0.0349\n",
      "[flaml.automl.logger: 07-14 02:59:20] {2221} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 07-14 03:18:44] {2394} INFO -  at 14697.1s,\testimator rf's best error=0.0183,\tbest estimator rf's best error=0.0183\n",
      "[flaml.automl.logger: 07-14 03:18:44] {2221} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 07-14 03:35:55] {2394} INFO -  at 15728.0s,\testimator rf's best error=0.0183,\tbest estimator rf's best error=0.0183\n",
      "[flaml.automl.logger: 07-14 03:35:55] {2221} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 07-14 04:00:51] {2394} INFO -  at 17224.0s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 04:00:51] {2221} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 07-14 04:19:53] {2394} INFO -  at 18366.6s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 04:19:53] {2221} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 07-14 05:21:13] {2394} INFO -  at 22046.5s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 05:21:13] {2221} INFO - iteration 18, current learner rf\n",
      "[flaml.automl.logger: 07-14 05:40:37] {2394} INFO -  at 23210.3s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 05:40:37] {2221} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 07-14 05:50:13] {2394} INFO -  at 23786.0s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 05:50:13] {2221} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 07-14 06:32:13] {2394} INFO -  at 26306.3s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 06:32:13] {2221} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 07-14 06:52:19] {2394} INFO -  at 27512.5s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 06:52:19] {2221} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 07-14 07:00:47] {2394} INFO -  at 28019.8s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 07:00:47] {2221} INFO - iteration 23, current learner rf\n",
      "[flaml.automl.logger: 07-14 07:28:00] {2394} INFO -  at 29653.4s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 07:28:00] {2221} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 07-14 08:22:04] {2394} INFO -  at 32896.9s,\testimator rf's best error=0.0111,\tbest estimator rf's best error=0.0111\n",
      "[flaml.automl.logger: 07-14 08:22:04] {2221} INFO - iteration 25, current learner rf\n",
      "[flaml.automl.logger: 07-14 09:08:36] {2394} INFO -  at 35689.1s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 09:08:36] {2221} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.logger: 07-14 09:16:41] {2394} INFO -  at 36174.0s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 09:16:41] {2221} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 07-14 09:29:24] {2394} INFO -  at 36937.5s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 09:29:24] {2221} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 07-14 09:45:57] {2394} INFO -  at 37930.2s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 09:45:57] {2221} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 07-14 10:10:48] {2394} INFO -  at 39421.0s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 10:10:48] {2221} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 07-14 10:19:22] {2394} INFO -  at 39935.2s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 10:19:22] {2221} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 07-14 11:58:10] {2394} INFO -  at 45863.4s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 11:58:10] {2221} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 07-14 12:08:09] {2394} INFO -  at 46462.1s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 12:08:09] {2221} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 07-14 12:56:00] {2394} INFO -  at 49333.6s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 12:56:00] {2221} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 07-14 13:33:47] {2394} INFO -  at 51600.6s,\testimator rf's best error=0.0090,\tbest estimator rf's best error=0.0090\n",
      "[flaml.automl.logger: 07-14 13:50:07] {2630} INFO - retrain rf for 979.4s\n",
      "[flaml.automl.logger: 07-14 13:50:07] {2633} INFO - retrained model: RandomForestRegressor(max_features=0.8334539505729306, max_leaf_nodes=13325,\n",
      "                      n_estimators=45, n_jobs=50, random_state=12032022)\n",
      "[flaml.automl.logger: 07-14 13:50:07] {1941} INFO - fit succeeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-14 13:50:07] {1942} INFO - Time taken to find the best model: 35689.10792303085\n"
     ]
    }
   ],
   "source": [
    "def tune_randomforest(X, y):\n",
    "    \n",
    "    # define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    # define the optimization function\n",
    "    rf_tune = AutoML()\n",
    "    \n",
    "\n",
    "    # define the setting for optimization\n",
    "    \n",
    "    settings = {\n",
    "    \"time_budget\": 54000,  # total running time in seconds\n",
    "    \"metric\": 'mse',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": ['rf'],  # list of ML learners; we tune random forest in this experiment\n",
    "    \"task\": 'regression' # task type  \n",
    "\n",
    "}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # run flaml optimization to find the best hyperparameters for the random forest\n",
    "    rf_tune.fit(X_train, y_train,**settings,n_jobs=50,early_stop=True,hpo_method='bs',eval_method='cv',n_splits=5)\n",
    "    \n",
    "    # return the best hyperparameters and the best score\n",
    "    return rf_tune.best_config\n",
    "\n",
    "best_config = tune_randomforest(df.drop(columns=['sales']), df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d07dee10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 45, 'max_features': 0.8334539505729306, 'max_leaves': 13325}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87af3e",
   "metadata": {},
   "source": [
    "**The random forest model will be retrained using the tuned paramaters, and cross-validation and hold-out data evaluation will be done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "307c9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y):\n",
    "    # define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    \n",
    "\n",
    "    rf_model_tuned = RandomForestRegressor(max_features=0.8334539505729306, max_leaf_nodes=13325,\n",
    "                                            n_estimators=45, n_jobs=50, random_state=12032022)\n",
    "    \n",
    "    \n",
    "    # Perform 5-fold cross-validation using MAE, MSE, RMSE and R2 metric and printing their mean scores\n",
    "     # Define the scorer dictionary\n",
    "    \n",
    "    scorer = {\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'RMSE': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n",
    "    'R2': make_scorer(r2_score)\n",
    "}\n",
    "    \n",
    "\n",
    "    rf_scores = cross_validate(rf_model_tuned, X_train,y_train, cv=5, scoring= scorer,n_jobs=50)\n",
    "    \n",
    "    \n",
    "    # Compute mean scores and store in a pandas dataframe\n",
    "    cross_val_avg  = pd.DataFrame({\n",
    "    'MAE': rf_scores['test_MAE'].mean(),\n",
    "    'MSE': rf_scores['test_MSE'].mean(),\n",
    "    'RMSE': rf_scores['test_RMSE'].mean(),\n",
    "    'R2': rf_scores['test_R2'].mean()\n",
    "        \n",
    "}, index=[0])\n",
    "    \n",
    "    # Perform 5-fold cross-validation using MSE metric\n",
    "    \n",
    "    score = make_scorer(mean_squared_error)\n",
    "    rf_scores = cross_val_score(rf_model_tuned, X_train,y_train, cv=5, scoring=score,n_jobs=50)\n",
    "      # Save cross-validation scores to dataframe\n",
    "    cross_val = pd.DataFrame({\n",
    "        'Random Forest': rf_scores\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "    # Fit models on the train dataset\n",
    "    rf_model_tuned.fit(X_train,y_train)\n",
    "    \n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred_rf = rf_model_tuned.predict(X_test)\n",
    "\n",
    "    # Evaluate models with test data using MAE, MSE, RMSE, and R2 and save to dataframe\n",
    "    eval_test_data = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
    "        'Random Forest': [mean_absolute_error(y_test, y_pred_rf), \n",
    "                     mean_squared_error(y_test, y_pred_rf), \n",
    "                     np.sqrt(mean_squared_error(y_test, y_pred_rf)), \n",
    "                     r2_score(y_test, y_pred_rf)]\n",
    "    })\n",
    "\n",
    "    return cross_val_avg, cross_val, eval_test_data\n",
    "\n",
    "cross_val_avg, cross_val, eval_test_data = evaluate_models(df.drop(columns=['sales']), df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c1801cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.111101</td>\n",
       "      <td>0.999312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       MSE      RMSE        R2\n",
       "0  0.001159  0.015033  0.111101  0.999312"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f0136c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random Forest\n",
       "0       0.037394\n",
       "1       0.016963\n",
       "2       0.014537\n",
       "3       0.002444\n",
       "4       0.003830"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c5fa988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.033202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  Random Forest\n",
       "0    MAE       0.000641\n",
       "1    MSE       0.001102\n",
       "2   RMSE       0.033202\n",
       "3     R2       0.999916"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57f018",
   "metadata": {},
   "source": [
    "The tuned random forest model did not improve the accuracy. The pre-tuned model will be used to build the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8290d0",
   "metadata": {},
   "source": [
    "## Stacking Ensemble Training\n",
    "\n",
    "The experiment will allow the final estimator train the base predictions with the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "481b1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,cross_validate\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "def evaluate_stack(X, y):\n",
    "    # re-define the X and y variables\n",
    "    X = train_sample\n",
    "    y = test_sample\n",
    "    # create the train and test datasets\n",
    "    X_train = train_sample.drop(['sales'],axis=1)\n",
    "    y_train = train_sample['sales']\n",
    "    X_test = test_sample.drop(['sales'],axis=1)\n",
    "    y_test = test_sample['sales']\n",
    "    \n",
    "    #re-define the model functions with the tuned hyperparameter\n",
    "    lgb_model_tuned = LGBMRegressor(learning_rate=0.04057886825523183, max_bin=1023,\n",
    "                                    min_child_samples=9, n_estimators=4641, n_jobs=60, num_leaves=17,\n",
    "                                    reg_alpha=0.00770959807729146, reg_lambda=0.05173294676341311,\n",
    "                                    verbose=-1,objective='regression',metric='mse')\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_jobs=60)\n",
    "    \n",
    "    extratree = ExtraTreesRegressor(n_jobs=60)\n",
    "    \n",
    "    estimators = [('LightGBM', lgb_model_tuned),('Random Forest', rf_model)]\n",
    "    \n",
    "    #define the stacked model function\n",
    "    stacked_model = StackingRegressor(estimators=estimators,\n",
    "                                       final_estimator=extratree,passthrough=True,n_jobs=60)\n",
    "    \n",
    "    \n",
    "     # Perform 5-fold cross-validation using MAE, MSE, RMSE and R2 metric and printing their mean scores\n",
    "     # Define the scorer dictionary\n",
    "    \n",
    "    scorer = {\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'RMSE': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n",
    "    'R2': make_scorer(r2_score)\n",
    "}\n",
    "\n",
    "    stacked_scores = cross_validate(stacked_model, X_train,y_train, cv=5, scoring= scorer,n_jobs=60)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute mean scores and store in a pandas dataframe\n",
    "    cross_val_avg  = pd.DataFrame({\n",
    "        \n",
    "    'MAE': stacked_scores['test_MAE'].mean(),\n",
    "    'MSE': stacked_scores['test_MSE'].mean(),\n",
    "    'RMSE': stacked_scores['test_RMSE'].mean(),\n",
    "    'R2': stacked_scores['test_R2'].mean()\n",
    "\n",
    "        \n",
    "}, index=[0])\n",
    "    \n",
    "    # Perform 5-fold cross-validation using MSE metric\n",
    "    \n",
    "    score = make_scorer(mean_squared_error)\n",
    "    stacked_scores = cross_val_score(stacked_model, X_train,y_train, cv=5, scoring=score,n_jobs=60)\n",
    "    \n",
    "      # Save cross-validation scores to dataframe\n",
    "    cross_val = pd.DataFrame({\n",
    "        'Stacked_ensemble': stacked_scores\n",
    "    })\n",
    "    \n",
    "    return cross_val_avg, cross_val\n",
    "\n",
    "cross_val_avg, cross_val = evaluate_stack(df.drop(columns=['sales']), df['sales'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b91528a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.999339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       MSE      RMSE        R2\n",
       "0  0.000973  0.014936  0.107131  0.999339"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9eb28042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stacked_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stacked_ensemble\n",
       "0          0.038171\n",
       "1          0.014401\n",
       "2          0.013652\n",
       "3          0.001904\n",
       "4          0.002962"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2d8f5",
   "metadata": {},
   "source": [
    "The stacked ensemble with the final estimator training the base predictions with the original dataset did not overfit and outperformed the individual base learners based on the cross-validation evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7915f6",
   "metadata": {},
   "source": [
    "## Evaluate with hold-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbd538fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " #re-define the model functions with the tuned hyperparameter\n",
    "lgb_model_tuned =  LGBMRegressor(learning_rate=0.04057886825523183, max_bin=1023,\n",
    "                                    min_child_samples=9, n_estimators=4641, n_jobs=60, num_leaves=17,\n",
    "                                    reg_alpha=0.00770959807729146, reg_lambda=0.05173294676341311,\n",
    "                                    verbose=-1,objective='regression',metric='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc55eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_jobs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85890df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('LightGBM', lgb_model_tuned),('Random Forest', rf_model)]\n",
    "\n",
    "extratree = ExtraTreesRegressor(n_jobs=50)\n",
    "\n",
    "#define the stacked model function\n",
    "stacked_model = StackingRegressor(estimators=estimators,\n",
    "                                       final_estimator=extratree,passthrough=True,n_jobs=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c50e2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # re-define the X and y variables\n",
    "X = train_sample\n",
    "y = test_sample\n",
    "    # create the train and test datasets\n",
    "X_train = train_sample.drop(['sales'],axis=1)\n",
    "y_train = train_sample['sales']\n",
    "X_test = test_sample.drop(['sales'],axis=1)\n",
    "y_test = test_sample['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2dc0aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('LightGBM',\n",
       "                               LGBMRegressor(learning_rate=0.04057886825523183,\n",
       "                                             max_bin=1023, metric='mse',\n",
       "                                             min_child_samples=9,\n",
       "                                             n_estimators=4641, n_jobs=60,\n",
       "                                             num_leaves=17,\n",
       "                                             objective='regression',\n",
       "                                             reg_alpha=0.00770959807729146,\n",
       "                                             reg_lambda=0.05173294676341311,\n",
       "                                             verbose=-1)),\n",
       "                              ('Random Forest',\n",
       "                               RandomForestRegressor(n_jobs=60))],\n",
       "                  final_estimator=ExtraTreesRegressor(n_jobs=50), n_jobs=50,\n",
       "                  passthrough=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fee4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacked_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f933906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0003444317526379482\n",
      "MSE: 0.00041538446749075475\n",
      "RMSE: 0.020380982986371258\n",
      "R-squared:  0.9999684772854547\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, pred))\n",
    "print('MSE:', mean_squared_error(y_test, pred))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, pred)))\n",
    "print('R-squared: ',r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2919f",
   "metadata": {},
   "source": [
    "The evaluation of the stacked model using the hold-out data outperformed the individual base learners significantly. It's performance will now be compared with the MLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf9453",
   "metadata": {},
   "source": [
    "**Evaluation on Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69afb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = stacked_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2825c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.00020514446884526625\n",
      "MSE: 0.0011735364124736871\n",
      "RMSE: 0.0342569177316595\n",
      "R-squared:  0.9999371959716233\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_train, pred2))\n",
    "print('MSE:', mean_squared_error(y_train, pred2))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_train, pred2)))\n",
    "print('R-squared: ',r2_score(y_train,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c08e6cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fdce772b0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Our predictions\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test,pred)\n",
    "\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f59150",
   "metadata": {},
   "source": [
    "The scatterplot shows a good regression model. The regression line cuts across almost the entire datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b918c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x19fdc911ac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHqCAYAAADLbQ06AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAArs0lEQVR4nO3df1AU9p3/8Re/fxpB8dBcTbwIxFzDjAQCYqK2WuL0jEoJmrlSU51TE8BMTQd/RE01KqjJzMXBROKZOEzUxIsYx2D9lV68EY2IXo0Y89UBx1quJP5AQRcEYXe/f1j2xF+wCrsf1udjpjPufnb383nPmj5hwV0vu91uFwAAMJK3uw8AAADujlADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUnchut8tqtYr3kAEAdBZC3YlsNpu+/fZb2Wy2Lt2jvLy8S/dwJU+ax5NmkTxrHmYxlyfN01WzEOpuxm63q7m52WO+a/ekeTxpFsmz5mEWc3nSPF01C6EGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADObr7gMAMMfVxmZdb7E5LvcbEK3aay2SWuTv660egX7uOxzwkCLUAByut9iU/emfJUl2u2SxWBQaGiovL+mDXz/j5tMBDyde+gYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADCYW0J94sQJZWRkKCEhQc8//7yWLl2q69evS5KOHTumCRMmKC4uTiNHjtTmzZvb3Hfr1q1KSUnR4MGDlZaWpqNHjzrWrFarVqxYoaFDhyouLk6ZmZk6f/68Y72mpkZZWVlKSEhQUlKScnNz1dLS4lhvb28AAFzN5aG22Wx69dVXNXr0aJWVlamoqEj79+/X2rVrVVdXp+nTpys1NVWHDx9Wbm6uli1bpvLycknSoUOHtGTJEi1fvlyHDx/WuHHjlJmZqWvXrkmSCgoKdODAAW3ZskUlJSUKDAzUggULHHvPnDlTwcHBKikpUVFRkQ4ePKjCwkJJandvAADcweWhrqur04ULF2Sz2WS3228cwttbQUFB2rNnj8LCwpSRkSFfX18lJydr7Nix2rhxoyRp8+bNGjNmjOLj4+Xn56fJkycrPDxcO3bscKxPmzZN/fr1U2hoqObPn699+/apqqpKZ8+eVVlZmWbNmqWgoCD1799fWVlZjsdub28AANzB19UbhoeHa/LkyVqxYoXeeecdWa1WjRo1SpMnT9by5csVExPT5vZRUVEqKiqSJFVWVuqll166bf3kyZO6evWqfvzxxzb3j4iIUM+ePXXq1ClJUlhYmCIjIx3rAwcOVHV1ta5cuaKKiop77u0Mq9Xq9H2cfeyu3MOVPGkeT5nl718//98f7HbZ5SWp+87mKc+N5FmzSJ41j7Oz+Pj4dOh2Lg+1zWZTYGCg3nrrLaWnp+vs2bOaMWOG8vPzVV9fr6CgoDa3DwwMVENDgyTdc72+vl6SFBwcfNt669qt92293Hr/e+3tjOPHjzt9HxP3cCVPmqc7z9JvQLQsFkub6yx//++nqalJ3576zh3H6jTd+bm5lSfNInnWPB2dJT4+vkO3c3mov/rqK+3evVu7du2SJEVHRys7O1u5ubkaO3asrl692ub2jY2NCgkJkXQjrI2Njbeth4eHOyLb+vPqW+9vt9tvW2u9HBISoqCgoHvu7YzY2NgOf6XkLKvVquPHj3fpHq7kSfN4wiy111oUGhp644LdLkt9vUJDQiQvLwUEBGjw4MFuPd/98oTnppUnzSJ51jxdNYvLQ/3DDz84fsPbcQhfX/n5+SkmJkYHDhxos1ZZWano6GhJN6JeUVFx2/rw4cPVs2dPRUZGqrKy0vES9oULF1RbW6uYmBjZbDbV1tbq4sWLioiIkCSdPn1affv2VY8ePdrd2xk+Pj5d/hfOFXu4kifN071naZHXjVe5HS93y8vLcV33neuG7v3ctOVJs0ieNU9nz+LyXyZ7/vnndeHCBX344YeyWq2qqqpSQUGBxo4dq5SUFF28eFGFhYVqbm5WaWmpiouLHT+XTk9PV3FxsUpLS9Xc3KzCwkLV1NQoJSVFkpSWlqaCggJVVVXJYrEoLy9PiYmJeuyxxzRgwADFx8crLy9PFotFVVVVWr16tdLT0yWp3b0BAHAHl39HHRUVpTVr1mjlypX66KOP1KNHD40bN07Z2dny9/fXunXrlJubq/z8fPXq1UsLFizQkCFDJEnJyclauHChFi1apHPnzikqKkpr165VWFiYJCk7O1stLS3KyMhQfX29kpKStHLlSsfe+fn5Wrx4sUaNGiVvb2+lpqYqKytL0o1fcrvX3gAAuIPLQy1JQ4cO1dChQ++4Fhsbq02bNt31vuPHj9f48ePvuObn56ecnBzl5OTccT0iIkL5+fl3fez29gYAwNV4C1EAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYG4JdW1trWbPnq2kpCQ9++yzysrK0vnz5yVJx44d04QJExQXF6eRI0dq8+bNbe67detWpaSkaPDgwUpLS9PRo0cda1arVStWrNDQoUMVFxenzMxMx+NKUk1NjbKyspSQkKCkpCTl5uaqpaXFsd7e3gAAuJpbQv3666+roaFBX331lfbu3SsfHx+99dZbqqur0/Tp05WamqrDhw8rNzdXy5YtU3l5uSTp0KFDWrJkiZYvX67Dhw9r3LhxyszM1LVr1yRJBQUFOnDggLZs2aKSkhIFBgZqwYIFjn1nzpyp4OBglZSUqKioSAcPHlRhYaEktbs3AADu4PJQf/fddzp27JiWL1+uRx55RKGhoVqyZIlycnK0Z88ehYWFKSMjQ76+vkpOTtbYsWO1ceNGSdLmzZs1ZswYxcfHy8/PT5MnT1Z4eLh27NjhWJ82bZr69eun0NBQzZ8/X/v27VNVVZXOnj2rsrIyzZo1S0FBQerfv7+ysrIcj93e3gAAuIOvqzcsLy9XVFSUPv/8c3322We6du2ahg0bpjlz5qiiokIxMTFtbh8VFaWioiJJUmVlpV566aXb1k+ePKmrV6/qxx9/bHP/iIgI9ezZU6dOnZIkhYWFKTIy0rE+cOBAVVdX68qVK+3u7Qyr1er0fZx97K7cw5U8aR5PmcVuv+UPdrvs8pLUfWfzlOdG8qxZJM+ax9lZfHx8OnQ7l4e6rq5Op06d0tNPP62tW7eqsbFRs2fP1pw5cxQREaGgoKA2tw8MDFRDQ4Mkqb6+/q7r9fX1kqTg4ODb1lvXbr1v6+XW+99rb2ccP37c6fuYuIcredI83XmWfgOiZbFY2lxn+ft/P01NTfr21HfuOFan6c7Pza08aRbJs+bp6Czx8fEdup3LQ+3v7y9Jmj9/vgICAhQaGqqZM2dq4sSJSktLU2NjY5vbNzY2KiQkRNKNsN5pPTw83BHZ1p9X33p/u91+21rr5ZCQEAUFBenq1at33dsZsbGxHf5KyVlWq1XHjx/v0j1cyZPm8YRZaq+1KDQ09MYFu12W+nqFhoRIXl4KCAjQ4MGD3Xq+++UJz00rT5pF8qx5umoWl4c6KipKNptNzc3NCggIkCTZbDZJ0lNPPaVPP/20ze0rKysVHR0tSYqOjlZFRcVt68OHD1fPnj0VGRmpyspKx0vYFy5cUG1trWJiYmSz2VRbW6uLFy8qIiJCknT69Gn17dtXPXr0UExMjA4cOHDXvZ3h4+PT5X/hXLGHK3nSPN17lhZ53XiV2/Fyt7y8HNd137lu6N7PTVueNIvkWfN09iwu/2WyoUOHqn///po3b57q6+t16dIlvffee/rFL36hF198URcvXlRhYaGam5tVWlqq4uJix8+l09PTVVxcrNLSUjU3N6uwsFA1NTVKSUmRJKWlpamgoEBVVVWyWCzKy8tTYmKiHnvsMQ0YMEDx8fHKy8uTxWJRVVWVVq9erfT0dElSSkrKPfcGAMAdXB5qPz8/rV+/Xj4+Pho9erRGjx6tvn37Ki8vT+Hh4Vq3bp127dqlpKQkLViwQAsWLNCQIUMkScnJyVq4cKEWLVqkxMRE/fGPf9TatWsVFhYmScrOztaIESOUkZGhESNGqKmpSStXrnTsnZ+fr5aWFo0aNUoTJ07UsGHDlJWVJUnt7g0AgDu4/KVvSYqMjNR77713x7XY2Fht2rTprvcdP368xo8ff8c1Pz8/5eTkKCcn547rERERys/Pv+tjt7c3AACuxluIAgBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGKzTQm2xWDrroQAAwN85HerExMQ7Xv+zn/3sQc8CAABu4duRG509e1Z/+MMfZLfbZbFY9Morr7RZt1gseuSRR7rkgAAAPMw6FOrHH39cL7zwgi5fvqw///nPt31X7e/vr5EjR3bJAQEAeJh1KNSSlJGRIUn6yU9+otTU1K46DwAAuEmHQ90qNTVV5eXlOnPmjOx2+21rAACg8zgd6n//93/X2rVr1adPH/n6/t/dvby8CDUAAJ3M6VBv27ZNH374oUaMGNEV5wEAADdx+p9nNTQ0aPjw4V1xFgAAcAunQ/2zn/1MxcXFXXEWAABwC6df+m5qatLcuXP14YcfKiIios3aJ5980mkHAwAA9xHqmJgYxcTEdMVZAADALZwO9YwZM7riHAAA4A6cDvWbb75517Vly5Y90GEAAEBbD/zpWZcvX9bOnTsVHBzcGecBAAA3cfo76jt91/zNN9/o008/7ZQDAQCA/9Mpn0c9dOhQlZaWdsZDAQCAmzj9HfWtWlpatH37dvXq1aszzgMAAG7idKgHDRokLy+vNtf5+Pho/vz5nXYoAABwg9OhvvVNTby9vfX444+rT58+nXYoAABwg9M/o05MTFRCQoICAwN18eJFSVLv3r07/WAAAOA+vqO+cOGCXnvtNZ08eVJhYWG6fPmyBgwYoHXr1qlv375dcUYAAB5aTn9HvWLFCg0YMEBlZWU6cOCADh06pKeeeoo3OwEAoAs4/R11aWmpdu3apZCQEElSjx49tGjRIo0aNarTDwcAwMPO6e+obTbbbb/17eXlJT8/v047FAAAuMHpUCclJWnRokVqaGiQJNXX12vRokVKTEzs9MMBAPCwc/ql71mzZmnKlClKTExUWFiYamtrNXDgQP3Hf/xHV5wPAICHmlOhttvtamlp0R//+EcdOXJENTU1+tvf/qZ/+7d/k4+PT1edEQCAh1aHX/puaGjQv/7rv+qdd96Rr6+vhgwZoiFDhuj999/XpEmTHC+FAwCAztPhUBcUFMjPz09vv/2247revXtr7969amlp0Zo1a7rkgAAAPMw6HOrdu3dr6dKlt70LWe/evfX2229r165dnX44AAAedh0OdU1NjR5//PE7rj311FO6cOFCpx0KAADc0OFQh4aG6vLly3dcq62tVVBQUKcdCgAA3NDhUCcnJ2vjxo13XPv00081ePDgzjoTAAD4uw7/86xXX31VaWlpunz5sv7lX/5Fffr00fnz57Vz505t2bJFGzZs6MpzAgDwUOpwqP/pn/5JH3/8sRYuXKiNGzfKy8tLdrtdMTExWrt2rZ5++umuPCcAAA8lp97w5JlnnlFxcbGqqqp06dIl9enTR48++mhXnQ0AgIee028hKkn9+/dX//79O/ssAADgFk5/KAcAAHAdQg0AgMEINQAABiPUAAAYjFADAGAwt4baarVq0qRJmjt3ruO6Y8eOacKECYqLi9PIkSO1efPmNvfZunWrUlJSNHjwYKWlpeno0aNtHm/FihUaOnSo4uLilJmZqfPnzzvWa2pqlJWVpYSEBCUlJSk3N1ctLS0d3hsAAFdza6jff/99HTlyxHG5rq5O06dPV2pqqg4fPqzc3FwtW7ZM5eXlkqRDhw5pyZIlWr58uQ4fPqxx48YpMzNT165dk3TjozgPHDigLVu2qKSkRIGBgVqwYIHj8WfOnKng4GCVlJSoqKhIBw8eVGFhYYf2BgDAHdwW6oMHD2rPnj164YUXHNft2bNHYWFhysjIkK+vr5KTkzV27FjHe4xv3rxZY8aMUXx8vPz8/DR58mSFh4drx44djvVp06apX79+Cg0N1fz587Vv3z5VVVXp7NmzKisr06xZsxQUFKT+/fsrKyvL8djt7Q0AgDvc1xuePKiamhrNnz9fq1evdnxHK0kVFRWKiYlpc9uoqCgVFRVJkiorK/XSSy/dtn7y5EldvXpVP/74Y5v7R0REqGfPnjp16pQkKSwsTJGRkY71gQMHqrq6WleuXGl3b2dYrVan7+PsY3flHq7kSfN4yix2+y1/sNtll5ek7jubpzw3kmfNInnWPM7O4uPj06HbuTzUNptNs2bN0pQpUzRo0KA2a/X19bd9XGZgYKAaGhraXa+vr5ckBQcH37beunbrfVsvt97/Xns74/jx407fx8Q9XMmT5unOs/QbEC2LxdLmOsvf//tpamrSt6e+c8exOk13fm5u5UmzSJ41T0dniY+P79DtXB7qNWvWyN/fX5MmTbptLSgoSFevXm1zXWNjo0JCQhzrjY2Nt62Hh4c7Itv68+pb72+3229ba70cEhLS7t7OiI2N7fBXSs6yWq06fvx4l+7hSp40jyfMUnutRaGhoTcu2O2y1NcrNCRE8vJSQEBAt/04W094blp50iySZ83TVbO4PNTbtm3T+fPnlZCQIEmO8P7pT3/S7NmzdeDAgTa3r6ysVHR0tCQpOjpaFRUVt60PHz5cPXv2VGRkpCorKx0vYV+4cEG1tbWKiYmRzWZTbW2tLl68qIiICEnS6dOn1bdvX/Xo0UMxMTH33NsZPj4+Xf4XzhV7uJInzdO9Z2mR141XuR0vd8vLy3Fd953rhu793LTlSbNInjVPZ8/i8l8m27Vrl/785z/ryJEjOnLkiF588UW9+OKLOnLkiFJSUnTx4kUVFhaqublZpaWlKi4udvxcOj09XcXFxSotLVVzc7MKCwtVU1OjlJQUSVJaWpoKCgpUVVUli8WivLw8JSYm6rHHHtOAAQMUHx+vvLw8WSwWVVVVafXq1UpPT5ekdvcGAMAd3PLLZHcTHh6udevWKTc3V/n5+erVq5cWLFigIUOGSJKSk5O1cOFCLVq0SOfOnVNUVJTWrl2rsLAwSVJ2drZaWlqUkZGh+vp6JSUlaeXKlY7Hz8/P1+LFizVq1Ch5e3srNTVVWVlZHdobAAB3cHuoly9f3uZybGysNm3adNfbjx8/XuPHj7/jmp+fn3JycpSTk3PH9YiICOXn59/1sdvbGwAAV+MtRAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYG4J9cmTJzVlyhQlJibqueee0+zZs3Xp0iVJ0rFjxzRhwgTFxcVp5MiR2rx5c5v7bt26VSkpKRo8eLDS0tJ09OhRx5rVatWKFSs0dOhQxcXFKTMzU+fPn3es19TUKCsrSwkJCUpKSlJubq5aWloc6+3tDQCAq7k81I2NjZo6dari4uK0f/9+bd++XbW1tZo3b57q6uo0ffp0paam6vDhw8rNzdWyZctUXl4uSTp06JCWLFmi5cuX6/Dhwxo3bpwyMzN17do1SVJBQYEOHDigLVu2qKSkRIGBgVqwYIFj75kzZyo4OFglJSUqKirSwYMHVVhYKEnt7g0AgDu4PNTV1dUaNGiQsrOz5e/vr/DwcL388ss6fPiw9uzZo7CwMGVkZMjX11fJyckaO3asNm7cKEnavHmzxowZo/j4ePn5+Wny5MkKDw/Xjh07HOvTpk1Tv379FBoaqvnz52vfvn2qqqrS2bNnVVZWplmzZikoKEj9+/dXVlaW47Hb2xsAAHdweaifeOIJffTRR/Lx8XFct3v3bv30pz9VRUWFYmJi2tw+KipKJ0+elCRVVlbedf3q1av68ccf26xHRESoZ8+eOnXqlCoqKhQWFqbIyEjH+sCBA1VdXa0rV660uzcAAO7g687N7Xa7Vq5cqb1792rDhg365JNPFBQU1OY2gYGBamhokCTV19ffdb2+vl6SFBwcfNt669qt92293Hr/e+3tDKvV6vR9nH3srtzDlTxpHk+ZxW6/5Q92u+zyktR9Z/OU50byrFkkz5rH2Vlu/ob1XtwWaovFojfffFMnTpzQhg0b9OSTTyooKEhXr15tc7vGxkaFhIRIuhHWxsbG29bDw8MdkW39efWt97fb7bettV4OCQlpd29nHD9+3On7mLiHK3nSPN15ln4DomWxWNpcZ/n7F7pNTU369tR37jhWp+nOz82tPGkWybPm6egs8fHxHbqdW0L917/+VdOmTdOjjz6qoqIi9erVS5IUExOjAwcOtLltZWWloqOjJUnR0dGqqKi4bX348OHq2bOnIiMj27w8fuHCBdXW1iomJkY2m021tbW6ePGiIiIiJEmnT59W37591aNHj3b3dkZsbGyHv1JyltVq1fHjx7t0D1fypHk8YZbaay0KDQ29ccFul6W+XqEhIZKXlwICAjR48GC3nu9+ecJz08qTZpE8a56umsXloa6rq9Nvf/tbDRkyRLm5ufL2/r8fk6ekpOjdd99VYWGhMjIy9D//8z8qLi7W6tWrJUnp6enKzs7WL3/5S8XHx2vjxo2qqalRSkqKJCktLU0FBQWKjY1VeHi48vLylJiYqMcee0zSja9e8vLytHjxYl2+fFmrV69Wenp6h/Z2ho+PT5f/hXPFHq7kSfN071la5HXjVW7Hy93y8nJc133nuqF7PzdtedIskmfN09mzuDzUX3zxhaqrq7Vz507t2rWrzdrRo0e1bt065ebmKj8/X7169dKCBQs0ZMgQSVJycrIWLlyoRYsW6dy5c4qKitLatWsVFhYmScrOzlZLS4syMjJUX1+vpKQkrVy50vH4+fn5Wrx4sUaNGiVvb2+lpqYqKytLkhQeHn7PvQEAcAeXh3rKlCmaMmXKXddjY2O1adOmu66PHz9e48ePv+Oan5+fcnJylJOTc8f1iIgI5efn3/feAAC4Gm8hCgCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUN+ipqZGWVlZSkhIUFJSknJzc9XS0uLuYwEAHlKE+hYzZ85UcHCwSkpKVFRUpIMHD6qwsNDdxwIAPKQI9U3Onj2rsrIyzZo1S0FBQerfv7+ysrK0ceNGdx8NAPCQItQ3qaioUFhYmCIjIx3XDRw4UNXV1bpy5YobTwYAeFj5uvsAJqmvr1dQUFCb61ovNzQ06JFHHrnn/e12uyTp+vXr8vHx6ZIzWq3WLt/DlTxpHk+YxWa1ys+r9ZJdAT6Sv5dd8vKSzWrV9evX3Xm8++YJz00rT5pF8qx5nJ3Fx8dH3t7e8vLyuuftCPVNgoODde3atTbXtV4OCQlp9/42m02S9P3333f+4W7hij1cyZPm6e6zzHzG/6ZLAY4//bXy/7n+MJ2suz83N/OkWSTPmseZWQYPHtxu1An1TaKjo1VbW6uLFy8qIiJCknT69Gn17dtXPXr0aPf+vr6+io2N7dBXSAAAeHu3/xNoL3vr67WQJP36179W3759tXjxYl2+fFmZmZkaPXq0Xn/9dXcfDQDwECLUt7h48aIWL16sQ4cOydvbW6mpqcrJyen2PzsBAHRPhBoAAIPxz7MAADAYoQYAwGCEGgAAgxFqAAAMRqi7qaamJi1dulTPPfec4uPj9dvf/lanT59297E6xaxZszRp0iR3H+O+/e///q9mzJihIUOGKCkpSVlZWaqqqnL3sTrMkz5B7uTJk5oyZYoSExP13HPPafbs2bp06ZK7j/VArFarJk2apLlz57r7KA+ktrZWs2fPVlJSkp599lllZWXp/Pnz7j7WfTtx4oQyMjKUkJCg559/XkuXLu20d/Ij1N3UokWLdOLECW3dulUHDx7UwIED9bvf/c7dx3pgRUVF2r59u7uP8UCys7PVs2dPff311/r6668VFhamrKwsdx+rwzzlE+QaGxs1depUxcXFaf/+/dq+fbtqa2s1b948dx/tgbz//vs6cuSIu4/xwF5//XU1NDToq6++0t69e+Xj46O33nrL3ce6LzabTa+++qpGjx6tsrIyFRUVaf/+/Vq7dm2nPD7vTNYN1dTUaNu2bdqxY4f+4R/+QZKUk5OjM2fOyG63d9t3RausrNTq1as1YcIEnTlzxt3HuS91dXWKiIjQ7373OwUHB0uSXnnlFY0fP151dXXq2bOnm094b62fILdv3742nyD37rvvaurUqe4+nlOqq6s1aNAgZWdny8fHR/7+/nr55Zc1e/Zsdx/tvh08eFB79uzRCy+84O6jPJDvvvtOx44d0zfffKPQ0FBJ0pIlS3ThwgU3n+z+1NXV6cKFC7LZbI7PfPD29r7tsyPuF6E2VGNjo86dO3fHtTNnzqhHjx769ttvlZ2drUuXLik+Pl7z5s0zNtL3mqdPnz7y9vbWG2+8oYULF6q8vNzoULc3y8cff9zmut27d+sf//EfjY+01P4nyLX3wTQmeeKJJ/TRRx+1uW737t366U9/6qYTPZiamhrNnz9fq1ev7pavcNysvLxcUVFR+vzzz/XZZ5/p2rVrGjZsmObMmePuo92X8PBwTZ48WStWrNA777wjq9WqUaNGafLkyZ3y+ITaUMeOHdMrr7xyx7V3331XV69e1Z49e7R+/Xr5+flp8eLFeu2117R161Yj30XtXvN88MEH+vrrr/Xcc89pxIgRKi8vd/HpnNPeLL/4xS8clz/77DOtW7dOBQUFrjreA3nQT5Azld1u18qVK7V3715t2LDB3cdxms1m06xZszRlyhQNGjTI3cd5YHV1dTp16pSefvppbd26VY2NjZo9e7bmzJmjNWvWuPt4TrPZbAoMDNRbb72l9PR0nT17VjNmzFB+fr5mzpz5wI9PqA2VlJSkU6dO3XFt165dslqtmjNnjnr16iVJevPNN5WcnKwzZ84oKirKlUftkHvN8+WXX+rkyZPatGmTi091f+41S6vr169r2bJl2rFjh9asWaMhQ4a46HQP5kE/Qc5EFotFb775pk6cOKENGzboySefdPeRnLZmzRr5+/t361+yvJm//41PaJs/f74CAgIUGhqqmTNnauLEiaqvr+92f9e++uor7d69W7t27ZJ04wOesrOzlZubS6gfVq0hvvk3Cls/B7U7viPstm3bdObMGQ0dOlTSjd9ot1qtSkhI0JdffqlHH33UzSd0zqVLl5SZmanr16+rqKhI/fv3d/eROuxBP0HONH/96181bdo0PfrooyoqKnJ8YdvdbNu2TefPn1dCQoKkGz9+kaQ//elP3fIXy6KiomSz2dTc3KyAgBsfpdr6McHd8f/Dfvjhh9t+w9vX11d+fn6d8vi813c39Zvf/EZWq1UffPCBAgIC9Ic//EFnzpzRF1984e6jPbBVq1aprKxM69evd/dRnNbc3KyXX35Z4eHh+uCDDxQYGOjuIznNUz5Brq6uTqmpqRoyZIhyc3M79HGC3UXrP81avny5m09yf5qbmzVmzBgNGjRIy5YtU1NTk9544w316NFD77//vruP57TKykr96le/UnZ2tqZNm6bq6mplZWXp+eef75Sfu3vO39yHTEFBgaKjo5Wamqphw4apoaFBq1evdvexHnp79+7ViRMndPjwYSUnJysuLs7xv+rqancfr0Py8/PV0tKiUaNGaeLEiRo2bFi3+udlrb744gtVV1dr586dio+Pb/NcwL38/Py0fv16+fj4aPTo0Ro9erT69u2rvLw8dx/tvkRFRWnNmjX6+uuvlZSUpFdeeUUjR47UG2+80SmPz3fUAAAYjO+oAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAXSZVatWecwHSQDuQqgBADAYoQbQIatWrdKIESOUmJiol156Sf/1X/8lSSoqKlJaWpqSkpIUFxenV199VZcuXbrjY3zzzTdKT09XQkKCxowZoy+//NKxVlFRoYyMDD377LP6+c9/rjlz5shisbhkNsBkhBpAu0pLS/Wf//mf2rx5sw4dOqQJEyZo/vz5OnbsmJYuXapFixbp0KFD2rlzp/7yl7/ok08+ue0xTp48qczMTE2fPl2HDh3SkiVLlJeXp5KSEknS22+/reTkZJWVlWnLli36/vvvtXnzZlePChiHz6MG0K6AgADV1dXp888/189//nNNmDBBL7/8spqamrR9+3b95Cc/UV1dnc6fP69evXrp3Llztz3Gpk2bNGrUKL3wwguSpGeeeUYTJ07Uxo0bNWzYMAUEBKikpEQDBw5UcnKytm3b5lEfTQncL0INoF1xcXFatWqV1q9fr48++kiBgYGaNGmSpk2bpk8++UTFxcUKDg7Wk08+KYvFojt9KN/f/vY3lZaWKiEhwXGd1WrVY489JklauXKlVq1apffee0+///3v9cwzz2jRokWKjo522ZyAiQg1gHZVV1erd+/e+vjjj3X9+nUdPHhQM2bMkN1u14EDB1RcXKyIiAhJ0muvvXbHx+jbt69+9atfafHixY7rzp8/L7vdLpvNpu+//16vv/665s2bpx9++EHLli3T3LlztWXLFpfMCJiK15UAtOv48eOaOnWqTp48KX9/f/Xu3VuS9O2338rX11d+fn5qaWnRtm3bVFJSoubm5tseIz09Xdu3b9f+/ftls9n0l7/8Rb/5zW+0bt06eXt7a+nSpVq5cqWamprUq1cvBQQEKDw83NWjAsbxst/pNSoAuMWaNWu0adMmXb58Wb1799bUqVP1y1/+UnPnzlVZWZkCAgL0z//8z3riiSdUWlqq4uJirVq1SmVlZVq/fr0k6b//+7+Vn5+vs2fPKigoSC+++KJ+//vfy9/fX6dPn9aSJUt04sQJ2Ww2Pfvss1q4cKH69evn5skB9yLUAAAYjJe+AQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADPb/AZDejduAQSbQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.displot((y_test-pred),bins=50) # plot a residual histogram by passing the y_test-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c7c2d",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f81bcdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STACKED_ENSEMBLE_MODEL_PHD2.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle in a file\n",
    "filename = 'STACKED_ENSEMBLE_MODEL_PHD2.pkl'\n",
    "joblib.dump(stacked_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b3468e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>simple_moving_average</th>\n",
       "      <th>exp_weighted_moving_average</th>\n",
       "      <th>cum_moving_average</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45113258</th>\n",
       "      <td>0</td>\n",
       "      <td>1885</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.392841</td>\n",
       "      <td>1.427775</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45282441</th>\n",
       "      <td>2</td>\n",
       "      <td>1885</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.007385</td>\n",
       "      <td>1.427358</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45172254</th>\n",
       "      <td>0</td>\n",
       "      <td>1885</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>1.434569</td>\n",
       "      <td>1.427874</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45172261</th>\n",
       "      <td>0</td>\n",
       "      <td>1885</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>3.061044</td>\n",
       "      <td>1.427875</td>\n",
       "      <td>42.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45282434</th>\n",
       "      <td>2</td>\n",
       "      <td>1885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>1.349851</td>\n",
       "      <td>1.427358</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state_id     d  sales  month  year  snap_CA  snap_TX  snap_WI  \\\n",
       "45113258         0  1885      1      3  2016        0        0        0   \n",
       "45282441         2  1885      1      3  2016        0        0        0   \n",
       "45172254         0  1885      5      3  2016        0        0        0   \n",
       "45172261         0  1885     17      3  2016        0        0        0   \n",
       "45282434         2  1885      0      3  2016        0        0        0   \n",
       "\n",
       "          sell_price  simple_moving_average  exp_weighted_moving_average  \\\n",
       "45113258        8.26               1.071429                     1.392841   \n",
       "45282441        2.68               1.357143                     1.007385   \n",
       "45172254        1.00               0.892857                     1.434569   \n",
       "45172261        2.48               1.928571                     3.061044   \n",
       "45282434        1.98               1.607143                     1.349851   \n",
       "\n",
       "          cum_moving_average  total_price  \n",
       "45113258            1.427775         8.26  \n",
       "45282441            1.427358         2.68  \n",
       "45172254            1.427874         5.00  \n",
       "45172261            1.427875        42.16  \n",
       "45282434            1.427358         0.00  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.head() # the hold-out dataset will saved for evaluation of the frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3afe41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.to_csv('holdout_sample_PHD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bb99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
